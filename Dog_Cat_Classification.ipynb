{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "HpqLXYGpGE5m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
        "dataset_path = \"cats_and_dogs.zip\"\n",
        "\n",
        "if not os.path.exists(\"dataset\"):\n",
        "    print(\"Downloading dataset...\")\n",
        "    response = requests.get(url)\n",
        "    with open(dataset_path, 'wb') as file:\n",
        "        file.write(response.content)"
      ],
      "metadata": {
        "id": "TUrVq7smGIFN"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Extract dataset\n",
        "    with ZipFile(dataset_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"dataset\")\n"
      ],
      "metadata": {
        "id": "7Cu1gUYuGLkj"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess images\n",
        "def preprocess_image(image_path, size=(16, 16)):  # Reduced size for faster processing\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, size)\n",
        "        image = image / 255.0  # Normalize\n",
        "        return image\n",
        "    except:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "sC1zi8NYGOHp"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_dir, label_map, subset_size=None):\n",
        "    images, labels = [], []\n",
        "    for label, folder in label_map.items():\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "        for i, filename in enumerate(os.listdir(folder_path)):\n",
        "            if subset_size and i >= subset_size:\n",
        "                break\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            image = preprocess_image(file_path)\n",
        "            if image is not None:\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n"
      ],
      "metadata": {
        "id": "fTcB10rBKUvb"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data_dir = \"dataset/PetImages\"\n",
        "label_map = {0: \"Cat\", 1: \"Dog\"}\n",
        "subset_size = 5000  # Use a subset for faster training\n",
        "images, labels = load_data(data_dir, label_map, subset_size=subset_size)\n"
      ],
      "metadata": {
        "id": "8WSpJUX8KWut"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten images for ML models (non-CNN models)\n",
        "flattened_images = images.reshape(len(images), -1)"
      ],
      "metadata": {
        "id": "gIwM3nesKc_x"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "y_categorical = to_categorical(encoded_labels)\n"
      ],
      "metadata": {
        "id": "mOYXo8gLKgzT"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "cnn_X_train, cnn_X_test, cnn_y_train, cnn_y_test = train_test_split(images, y_categorical, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "-R6sso0WKkqn"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SVM\n",
        "print(\"Training SVM...\")\n",
        "svm_model = SVC(kernel='linear', C=0.1, probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "joblib.dump(svm_model, \"svm_model.pkl\")\n",
        "print(\"SVM training completed and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLJj93Y0Knam",
        "outputId": "a1a71c40-f9d9-4d8f-f003-cbb315a0387b"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training SVM...\n",
            "SVM training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Random Forest\n",
        "print(\"Training Random Forest...\")\n",
        "rf_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "joblib.dump(rf_model, \"rf_model.pkl\")\n",
        "print(\"Random Forest training completed and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILjKT3sVKqEm",
        "outputId": "b9c48315-1fdf-433f-f371-41d0436ab800"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest...\n",
            "Random Forest training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression (SGD)\n",
        "print(\"Training Logistic Regression...\")\n",
        "sgd_model = SGDClassifier(loss='log_loss', max_iter=1000, random_state=42)  # Updated loss parameter\n",
        "sgd_model.fit(X_train, y_train)\n",
        "joblib.dump(sgd_model, \"sgd_model.pkl\")\n",
        "print(\"Logistic Regression training completed and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HlpR0y7Ksol",
        "outputId": "2c1c6cd2-54fc-4b5b-f736-4080b27b4e5f"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n",
            "Logistic Regression training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train CNN\n",
        "print(\"Training CNN...\")\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(16, 16, 3)),  # Fewer filters\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),  # Smaller dense layer\n",
        "    Dense(2, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrYYZn8rKw-a",
        "outputId": "b0a3f59b-4aad-41c5-89a3-edd7333a016c"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CNN...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(cnn_X_train, cnn_y_train, epochs=30, batch_size=64, validation_data=(cnn_X_test, cnn_y_test))  # Fewer epochs\n",
        "cnn_model.save(\"cnn_model.h5\")\n",
        "print(\"CNN training completed and saved.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49KRMku0K1sR",
        "outputId": "1544eb14-cc94-423e-e6b3-f7d7159addc2"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5327 - loss: 0.7079 - val_accuracy: 0.5767 - val_loss: 0.6635\n",
            "Epoch 2/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6457 - loss: 0.6325 - val_accuracy: 0.6147 - val_loss: 0.6540\n",
            "Epoch 3/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6695 - loss: 0.6044 - val_accuracy: 0.6879 - val_loss: 0.5903\n",
            "Epoch 4/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7077 - loss: 0.5732 - val_accuracy: 0.6889 - val_loss: 0.5803\n",
            "Epoch 5/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7181 - loss: 0.5581 - val_accuracy: 0.7069 - val_loss: 0.5681\n",
            "Epoch 6/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7329 - loss: 0.5339 - val_accuracy: 0.7014 - val_loss: 0.5702\n",
            "Epoch 7/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7481 - loss: 0.5120 - val_accuracy: 0.6979 - val_loss: 0.5727\n",
            "Epoch 8/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7510 - loss: 0.5088 - val_accuracy: 0.7049 - val_loss: 0.5692\n",
            "Epoch 9/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7627 - loss: 0.4914 - val_accuracy: 0.7124 - val_loss: 0.5643\n",
            "Epoch 10/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7769 - loss: 0.4721 - val_accuracy: 0.7129 - val_loss: 0.5650\n",
            "Epoch 11/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7990 - loss: 0.4457 - val_accuracy: 0.7335 - val_loss: 0.5313\n",
            "Epoch 12/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7980 - loss: 0.4349 - val_accuracy: 0.7234 - val_loss: 0.5405\n",
            "Epoch 13/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8098 - loss: 0.4184 - val_accuracy: 0.7154 - val_loss: 0.5572\n",
            "Epoch 14/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8259 - loss: 0.3920 - val_accuracy: 0.7219 - val_loss: 0.5708\n",
            "Epoch 15/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8380 - loss: 0.3707 - val_accuracy: 0.7214 - val_loss: 0.5595\n",
            "Epoch 16/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8511 - loss: 0.3501 - val_accuracy: 0.7104 - val_loss: 0.5700\n",
            "Epoch 17/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8598 - loss: 0.3307 - val_accuracy: 0.7109 - val_loss: 0.5733\n",
            "Epoch 18/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8700 - loss: 0.3138 - val_accuracy: 0.7034 - val_loss: 0.5937\n",
            "Epoch 19/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8827 - loss: 0.2943 - val_accuracy: 0.7114 - val_loss: 0.6007\n",
            "Epoch 20/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8924 - loss: 0.2726 - val_accuracy: 0.7164 - val_loss: 0.6073\n",
            "Epoch 21/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9033 - loss: 0.2582 - val_accuracy: 0.7064 - val_loss: 0.6322\n",
            "Epoch 22/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9166 - loss: 0.2312 - val_accuracy: 0.7129 - val_loss: 0.6495\n",
            "Epoch 23/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9198 - loss: 0.2219 - val_accuracy: 0.7169 - val_loss: 0.6661\n",
            "Epoch 24/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9279 - loss: 0.2068 - val_accuracy: 0.6989 - val_loss: 0.7382\n",
            "Epoch 25/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9377 - loss: 0.1855 - val_accuracy: 0.7184 - val_loss: 0.7028\n",
            "Epoch 26/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9532 - loss: 0.1629 - val_accuracy: 0.7239 - val_loss: 0.6997\n",
            "Epoch 27/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9514 - loss: 0.1566 - val_accuracy: 0.7164 - val_loss: 0.7486\n",
            "Epoch 28/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9601 - loss: 0.1396 - val_accuracy: 0.7074 - val_loss: 0.7795\n",
            "Epoch 29/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9654 - loss: 0.1290 - val_accuracy: 0.7134 - val_loss: 0.7996\n",
            "Epoch 30/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9733 - loss: 0.1085 - val_accuracy: 0.7139 - val_loss: 0.8212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load models for inference\n",
        "print(\"Loading models for inference...\")\n",
        "svm_model = joblib.load(\"svm_model.pkl\")\n",
        "rf_model = joblib.load(\"rf_model.pkl\")\n",
        "sgd_model = joblib.load(\"sgd_model.pkl\")\n",
        "cnn_model = load_model(\"cnn_model.h5\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgbUtG91K2rZ",
        "outputId": "faf206b8-6b26-4096-e4ff-b92461084b21"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models for inference...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on one sample image\n",
        "sample_image = X_test[0].reshape(1, -1)  # For non-CNN models\n",
        "cnn_sample_image = cnn_X_test[0].reshape(1, 16, 16, 3)  # For CNN\n",
        "\n",
        "print(\"SVM Prediction:\", label_encoder.inverse_transform(svm_model.predict(sample_image)))\n",
        "print(\"Random Forest Prediction:\", label_encoder.inverse_transform(rf_model.predict(sample_image)))\n",
        "print(\"Logistic Regression Prediction:\", label_encoder.inverse_transform(sgd_model.predict(sample_image)))\n",
        "print(\"CNN Prediction:\", label_encoder.inverse_transform(np.argmax(cnn_model.predict(cnn_sample_image), axis=1)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBhzzJbyK5Yf",
        "outputId": "3cf7e852-d289-4d8d-8c89-58e34dfa4516"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Prediction: [1]\n",
            "Random Forest Prediction: [1]\n",
            "Logistic Regression Prediction: [1]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "CNN Prediction: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train K-Means\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Suppress warnings for clean outpu\n",
        "print(\"Training K-Means...\")\n",
        "kmeans_model = KMeans(n_clusters=2, random_state=42)\n",
        "kmeans_model.fit(X_train)  # Unsupervised training on flattened images\n",
        "joblib.dump(kmeans_model, \"kmeans_model.pkl\")\n",
        "print(\"K-Means training completed and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qp-KSVaK95O",
        "outputId": "16d1766e-c08c-448e-a432-fc59d7a3f5c8"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training K-Means...\n",
            "K-Means training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok flask tensorflow scikit-learn pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjm4yLiILUUw",
        "outputId": "f95071bc-7bed-4e58-8637-8e80bda87bf9"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.11/dist-packages (0.0.25)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.0.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.6)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jupyter-dash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yQMOSXJLVDc",
        "outputId": "69787d90-3e18-4b6e-8689-5f53e833aec6"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jupyter-dash in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: dash in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (2.18.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (2.32.3)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (3.0.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (1.3.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (7.34.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (5.5.6)\n",
            "Requirement already satisfied: ansi2html in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (1.9.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from jupyter-dash) (1.6.0)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (3.0.6)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (5.24.1)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (5.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (4.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash->jupyter-dash) (75.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask->jupyter-dash) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from flask->jupyter-dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->jupyter-dash) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from flask->jupyter-dash) (1.9.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter-dash) (6.3.3)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->jupyter-dash) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->jupyter-dash) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->jupyter-dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->jupyter-dash) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->jupyter-dash) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from retrying->jupyter-dash) (1.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->jupyter-dash) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask->jupyter-dash) (3.0.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->jupyter-dash) (0.7.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash->jupyter-dash) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash->jupyter-dash) (24.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash->jupyter-dash) (3.21.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->jupyter-dash) (4.3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from jupyter_dash import JupyterDash\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "from dash.dependencies import Input, Output# Load Data\n",
        "\n"
      ],
      "metadata": {
        "id": "r7M4nvZrLcp5"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPlShDLWMtpL",
        "outputId": "4c17c9e8-9d43-4dfc-b516-d476d05de222"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask\n",
        "from pyngrok import ngrok\n"
      ],
      "metadata": {
        "id": "r8aBeogaLcyf"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.set_auth_token('2rtA0iFOshOyTXXDlIzIHBwedUK_2PCaFQ7BbWdGDScjzNtyo')\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(public_url)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lp_P7poLc0m",
        "outputId": "86986664-7eb2-4e1a-84f8-870b6081f971"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://27b5-34-19-64-63.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify, render_template\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pyngrok import ngrok\n",
        "\n"
      ],
      "metadata": {
        "id": "ryqKpwrhLc39"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n"
      ],
      "metadata": {
        "id": "SA4CLQpjLtxZ"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill ngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHIEUhiTPfia",
        "outputId": "ffced826-2de8-4033-ad4a-89248f5e7a5a"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-01-20T15:24:37+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-ed82cc32-6416-48a9-86c5-5d3232345520 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-01-20T15:24:37+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-5000-ed82cc32-6416-48a9-86c5-5d3232345520 err=\"failed to start tunnel: session closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-01-20T15:24:37+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-14f192ff-25ef-4af1-b1cb-a2805917bc3d acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up ngrok\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6zY05FyLtzl",
        "outputId": "48667b28-926b-47cc-ff2d-855b9e97c4fb"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://7de7-34-19-64-63.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load models\n",
        "svm_model = joblib.load(\"svm_model.pkl\")\n",
        "rf_model = joblib.load(\"rf_model.pkl\")\n",
        "sgd_model = joblib.load(\"sgd_model.pkl\")\n",
        "cnn_model = load_model(\"cnn_model.h5\")\n",
        "kmeans_model = joblib.load(\"kmeans_model.pkl\")  # Load KMeans model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki-9LkGiLt14",
        "outputId": "45358ed3-9cae-42e6-e6c6-f61ca149a937"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label map\n",
        "label_map = {0: \"Cat\", 1: \"Dog\"}\n",
        "\n",
        "def inverse_label(label_idx):\n",
        "    return label_map[label_idx]\n"
      ],
      "metadata": {
        "id": "fd2Twwa0Lt4R"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess image\n",
        "def preprocess_image(image_file, size=(16, 16)):\n",
        "    image = cv2.imdecode(np.frombuffer(image_file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
        "    if image is None:\n",
        "        return None\n",
        "    image = cv2.resize(image, size)\n",
        "    image = image / 255.0  # Normalize\n",
        "    return image\n",
        "\n"
      ],
      "metadata": {
        "id": "9WXo8FwJLt6P"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Root route\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"\"\"\n",
        "    <html>\n",
        "        <head><title>Cat and Dog Classifier</title></head>\n",
        "        <body>\n",
        "            <h1>Welcome to the Cat and  Classifier</h1>\n",
        "            <form action=\"/predict\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "                <label for=\"image\">Upload an image:</label>\n",
        "                <input type=\"file\" name=\"image\" accept=\"image/*\" required>\n",
        "                <button type=\"submit\">Predict</button>\n",
        "            </form>\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\"\n"
      ],
      "metadata": {
        "id": "P7In5OT3Lt8j"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction route\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'image' not in request.files:\n",
        "        return jsonify({'error': 'No image uploaded'}), 400\n",
        "\n",
        "    image_file = request.files['image']\n",
        "    image = preprocess_image(image_file)\n",
        "\n",
        "    if image is None:\n",
        "        return jsonify({'error': 'Invalid image format'}), 400\n"
      ],
      "metadata": {
        "id": "nxepnXR3L8xo"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_image = image.reshape(1, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "XPR4GzEfSXgR",
        "outputId": "78381767-a89f-45c6-d468-2412cff541fa"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'image' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-173-cf6d6e6bde0a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflattened_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN requires a 4D tensor\n",
        "cnn_image = image.reshape(1, 16, 16, 3)\n",
        "\n"
      ],
      "metadata": {
        "id": "ryRLr0wOMCMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "    svm_prediction = inverse_label(svm_model.predict(flattened_image)[0])\n",
        "    rf_prediction = inverse_label(rf_model.predict(flattened_image)[0])\n",
        "    sgd_prediction = inverse_label(sgd_model.predict(flattened_image)[0])\n",
        "    cnn_prediction = inverse_label(np.argmax(cnn_model.predict(cnn_image), axis=1)[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "jUcBuydgMCPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # KMeans prediction (returns cluster number)\n",
        "    kmeans_cluster = kmeans_model.predict(flattened_image)[0]\n",
        "    kmeans_prediction = f\"Cluster {kmeans_cluster}\"\n",
        "\n",
        "    return jsonify({\n",
        "        'svm_prediction': svm_prediction,\n",
        "        'rf_prediction': rf_prediction,\n",
        "        'sgd_prediction': sgd_prediction,\n",
        "        'cnn_prediction': cnn_prediction,\n",
        "        'kmeans_prediction': kmeans_prediction\n",
        "    })\n",
        "\n"
      ],
      "metadata": {
        "id": "DOd0N04_MCRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "app.run(port=5000)\n"
      ],
      "metadata": {
        "id": "ihBPdduOMCTL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}